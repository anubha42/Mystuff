{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubha42/Mystuff/blob/main/transformer_self_with_transformer_mod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORMER BLOCK INCLUDED BUT NO POSITIONAL ENCODING"
      ],
      "metadata": {
        "id": "tsqM2FMwErbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyU0EpHCmgB4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=4 #lenght of input sentence\n",
        "input_dim=512 #input\n",
        "d_model=512 #op of attention for every word\n",
        "batch_size=1 #parallel processing"
      ],
      "metadata": {
        "id": "sS2U9oF-mkpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand((batch_size, seq_length, input_dim )) #given to multihead attention no position encoding\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8OXfCTj6Fak",
        "outputId": "70b68685-7285-46a2-e2f0-dfe2796a34ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6116, 0.7832, 0.9442,  ..., 0.4138, 0.5190, 0.9550],\n",
            "         [0.9130, 0.4924, 0.9587,  ..., 0.5033, 0.6682, 0.1424],\n",
            "         [0.9066, 0.7734, 0.5284,  ..., 0.9671, 0.2104, 0.5681],\n",
            "         [0.7740, 0.6338, 0.5152,  ..., 0.1152, 0.7930, 0.8525]]])\n",
            "torch.Size([1, 4, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_layer=nn.Linear(input_dim, 3*d_model) #all concatenated 3 layers\n",
        "qkv=qkv_layer(x)\n",
        "qkv.shape  #1 batch 4 words of (3x512=1536 size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yekO-VjD6ass",
        "outputId": "7278645d-917e-44cd-dc8a-ada3b01ce862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads=8\n",
        "head_dim = d_model // num_heads #512/8=64\n",
        "qkv=qkv.reshape(batch_size, seq_length, num_heads, 3*head_dim) # 8x192= 1536\n",
        "print(qkv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRbhPnQh7ep2",
        "outputId": "e046c372-0145-434c-e7d8-14239e9cf7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 8, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv=qkv.permute(0,2,1,3) #(batch_Size, num_heads, seq_lenght, 3*head_dim) easy for computation\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9UTVhZ6-OcF",
        "outputId": "8c335d7f-c047-4ff5-866a-3b423f3d0e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q,k,v=qkv.chunk(3, dim=-1) #splitting into 3 along the last dimension\n",
        "q.shape,k.shape ,v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGkqG9E3-xAK",
        "outputId": "5bc3c482-02ba-4f88-b93e-07b0cc94cf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "d_k=q.size()[-1]\n",
        "scaled=torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_k)\n",
        "scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-q1qYHUA-kg",
        "outputId": "9b1ce331-6af6-4761-f788-803377adb028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask=torch.full(scaled.size(), float('-inf'))\n",
        "print(mask.shape)\n",
        "print(mask[0][1])\n",
        "mask=torch.triu(mask, diagonal=1) #upper triangular\n",
        "mask[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzzjLKhnAZfQ",
        "outputId": "86de3cdc-9d46-4257-d8a9-d1f9345d4ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 4, 4])\n",
            "tensor([[-inf, -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf, -inf]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(scaled+mask)[0][1] #mask for decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3AQsb8XBjst",
        "outputId": "6805f820-8f13-4e68-8032-d7e9753065de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0256,    -inf,    -inf,    -inf],\n",
              "        [-0.0351, -0.0300,    -inf,    -inf],\n",
              "        [-0.0325, -0.0903, -0.0160,    -inf],\n",
              "        [-0.0309, -0.0584,  0.0031, -0.0696]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q,k,v,mask=None):\n",
        "  d_k=q.size()[-1]\n",
        "  scaled=torch.matmul(q,k.transpose(-1,-2)) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled+=mask\n",
        "  attention=f.softmax(scaled,dim=-1)\n",
        "  value=torch.matmul(attention, v)\n",
        "  return value, attention"
      ],
      "metadata": {
        "id": "aJj55ddI_WGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eL0c7dG4Gz0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value, attention = scaled_dot_product(q,k,v, mask=None) #encoder\n",
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1n0ymTLCL-c",
        "outputId": "cd70649c-c15d-40ef-e325-17034a1c5288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value.shape #values after multiplication with attention"
      ],
      "metadata": {
        "id": "I83hV7SfCfSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88e90e6-8e1c-4340-e02d-d202a8c29145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention[0][0] #encoder attention"
      ],
      "metadata": {
        "id": "BHeFWAzIChat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55406f2-1de3-48d3-b8b5-536adfc29e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2484, 0.2585, 0.2361, 0.2569],\n",
              "        [0.2405, 0.2487, 0.2535, 0.2573],\n",
              "        [0.2399, 0.2574, 0.2399, 0.2629],\n",
              "        [0.2377, 0.2555, 0.2448, 0.2620]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value, attention = scaled_dot_product(q,k,v, mask=mask) #decoder attention\n",
        "attention[0][0]"
      ],
      "metadata": {
        "id": "5LIiJXDnCzyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fbc409-62f8-4569-ed05-ee97407d8fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4915, 0.5085, 0.0000, 0.0000],\n",
              "        [0.3254, 0.3492, 0.3254, 0.0000],\n",
              "        [0.2377, 0.2555, 0.2448, 0.2620]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenating values\n",
        "value=value.reshape(batch_size, seq_length, num_heads*head_dim)\n",
        "value.shape"
      ],
      "metadata": {
        "id": "dwbZOC3CDAVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2145ff70-1f23-4e16-e846-2236709385f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1=q.reshape(batch_size, seq_length, num_heads*head_dim)\n",
        "k1=k.reshape(batch_size, seq_length, num_heads*head_dim)\n",
        "v1=v.reshape(batch_size, seq_length, num_heads*head_dim)\n",
        "q1.shape"
      ],
      "metadata": {
        "id": "HTDK4g7AECml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6b5869-580f-4d93-fe5a-6e6f9405dc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_attn = nn.MultiheadAttention(d_model, num_heads) #using pytorch existing module\n",
        "attn_output, attn_output_weights = multihead_attn(q1,k1,v1)\n",
        "print(attn_output.shape)"
      ],
      "metadata": {
        "id": "qOarPwnbDgP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3f2edb-a8b9-4622-8d68-ef2bdf822df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_output_weights.shape\n",
        "attn_output"
      ],
      "metadata": {
        "id": "bvIKIbugEvG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525638f6-161b-4d1b-8550-b4d183f9fb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3938,  0.1054,  0.2816,  ...,  0.1038,  0.0654,  0.2489],\n",
              "         [ 0.1186, -0.0082, -0.1519,  ..., -0.0367, -0.0336,  0.1187],\n",
              "         [-0.1626,  0.1014, -0.0364,  ..., -0.1913,  0.0073, -0.1830],\n",
              "         [ 0.2504, -0.1506, -0.0716,  ..., -0.2099, -0.1274,  0.0694]]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE"
      ],
      "metadata": {
        "id": "yrqBEJUNdPH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)"
      ],
      "metadata": {
        "id": "icX-xueqFwKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "  def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "    super(PositionwiseFeedForward, self).__init__()\n",
        "    self.linear1=nn.Linear(d_model, hidden)\n",
        "    self.linear2=nn.Linear(hidden, d_model)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.dropout=nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.linear1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.dropout(x)\n",
        "    x=self.linear2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "H7wX087Y6hJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape)) # 512\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape)) # 512\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs : 30 x 200 x 512\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))] # [-1]\n",
        "        #print(f\"dims: {dims}\")\n",
        "        mean = inputs.mean(dim=dims, keepdim=True) #30 x 200 x 1\n",
        "        #print(f\"Mean ({mean.size()})\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True) # 30 x 200 x 512\n",
        "        std = (var + self.eps).sqrt() # 30 x 200 x 512\n",
        "        #print(f\"Standard Deviation  ({std.size()})\")\n",
        "        y = (inputs - mean) / std # 30 x 200 x 512\n",
        "        #print(f\"y: {y.size()}\")\n",
        "        out = self.gamma * y  + self.beta  # 30 x 200 x 512\n",
        "        #print(f\"out: {out.size()}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "g43OFxQl2uWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self,d_model, num_heads):\n",
        "    super().__init__()\n",
        "    #self.input_dim=input_dim\n",
        "    self.d_model=d_model\n",
        "    self.num_heads=num_heads\n",
        "    self.head_dim= d_model // num_heads\n",
        "    self.qkv_layer= nn.Linear(d_model, 3*d_model)\n",
        "    self.linear_layer=nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    batch_size, seq_length, d_model=x.size()\n",
        "    qkv=self.qkv_layer(x)\n",
        "    qkv=qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
        "    qkv=qkv.permute(0,2,1,3)\n",
        "    q,k,v=qkv.chunk(3, dim=-1)\n",
        "    value, attention= scaled_dot_product(q,k,v, mask=None)\n",
        "    print(f\"attention: {attention[0][0]}\")\n",
        "    print(f\"attention shape tensor: {attention.shape}\")\n",
        "    #attention=attention.detach().numpy()\n",
        "    #print(f\"after numpy attention shape:{attention.shape}\")\n",
        "    #plt.plot(attention[0][0]) #attention for first word\n",
        "    #plt.imshow(attention[0][0])\n",
        "    print(f\"values: {value[0][0]}\")\n",
        "    value=value.reshape(batch_size, seq_length, self.num_heads*self.head_dim)\n",
        "    out=self.linear_layer(value)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "YZ7naVPMFHIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadCrossAttention(nn.Module):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super().__init__()\n",
        "    self.d_model=d_model\n",
        "    self.num_heads=num_heads\n",
        "    self.head_dim= d_model // num_heads\n",
        "    self.kv_layer=nn.Linear(d_model, 2*d_model)\n",
        "    self.q_layer= nn.Linear(d_model, d_model)\n",
        "    self.linear_layer=nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self,x,y, mask=None):\n",
        "    batch_size, seq_length, d_model= x.size()\n",
        "    kv=self.kv_layer(x)\n",
        "    q=self.q_layer(y)\n",
        "    kv=kv.reshape(batch_size, seq_length, self.num_heads, 2*self.head_dim)\n",
        "    q=q.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
        "    kv=kv.permute(0,2,1,3)\n",
        "    q=q.permute(0,2,1,3)\n",
        "    k,v=kv.chunk(2,dim=-1)\n",
        "    value, attention= scaled_dot_product(q,k,v ,mask)\n",
        "    value=value.reshape(batch_size, seq_length, d_model)\n",
        "    out=self.linear_layer(value)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "5d8UKf0dQvX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.attention=MultiheadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm1=LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1=nn.Dropout(p=drop_prob)\n",
        "    self.ffn=PositionwiseFeedForward(d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "    self.norm2=LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2= nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def forward(self,x ):\n",
        "    residual_x=x\n",
        "    x=self.attention(x,mask=None)\n",
        "    x=self.dropout1(x)\n",
        "    x=self.norm1(x+residual_x)\n",
        "    #x=nn.LayerNorm(x+residual_x)\n",
        "    residual_x=x\n",
        "    x=self.ffn(x)\n",
        "    x=self.dropout2(x)\n",
        "    #x=nn.LayerNorm(x+residual_x)\n",
        "    x=self.norm2(x+residual_x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "u3keNRzz0tWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,d_model, ffn_hidden, num_heads, drop_prop, num_layers):\n",
        "    super().__init__()\n",
        "    self.layers=nn.Sequential(*(EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "    for _ in range(num_layers))) # *-> will take a list and deconstruct t in 5 layers\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.layers(x) #passing through all the encoder layers\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "rpQfng9Bhok5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.self_attention=MultiheadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1=nn.Dropout(p=drop_prob)\n",
        "    self.encoder_decoder_attention=MultiheadCrossAttention(d_model, num_heads=num_heads)\n",
        "    self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2=nn.Dropout(p=drop_prob)\n",
        "    self.ffn=PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "    self.norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout3=nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def forward(self,x, y, decoder_mask):\n",
        "    _y=y  #residual connections\n",
        "    #masked self attention\n",
        "    y=self.self_attention(y, mask=decoder_mask)\n",
        "    y=self.dropout1(y)\n",
        "    y=self.norm1(y+_y)\n",
        "    #y=nn.LayerNorm(y+_y)\n",
        "\n",
        "    _y=y # cross attention\n",
        "    y=self.encoder_decoder_attention(x,y, mask=None)\n",
        "    y=self.dropout2(y)\n",
        "    y=self.norm2(y+_y)\n",
        "    #y=nn.LayerNorm(y+_y)\n",
        "\n",
        "    _y=y #feed forward\n",
        "    y=self.ffn(y)\n",
        "    y=self.dropout3(y)\n",
        "    y=self.norm3(y+_y)\n",
        "    #y=nn.LayerNorm(y+_y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "ZxTYlTTFjUC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialDecoder(nn.Sequential): #because we cant pass more than 1 ip\n",
        "    def forward(self, *inputs):\n",
        "        x, y, mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, mask) #30 x 200 x 512\n",
        "        return y"
      ],
      "metadata": {
        "id": "Vvt68brriExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "    for _ in range(num_layers)])\n",
        "\n",
        "  def forward(self, x,y,mask):\n",
        "    y=self.layers(x,y,mask)\n",
        "    return y"
      ],
      "metadata": {
        "id": "IjTuuipyhjJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, d_model, ffn_hidden,num_heads, drop_prob ):\n",
        "    super().__init__()\n",
        "    #self.self_attention=MultiheadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.encoder=Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "    self.decoder=Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "\n",
        "  def forward(self, x, y, decoder_mask):\n",
        "    #x=self.self_attention(x)\n",
        "    x=self.encoder(x)\n",
        "    x=self.decoder(x, y, mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dGea6alL5--H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model=512\n",
        "num_heads=8\n",
        "batch_size=30\n",
        "drop_prob=0.1\n",
        "ffn_hidden=2048 #to add non linearity\n",
        "max_seq_length=200 # max number of words\n",
        "num_layers= 5 # number of encoders\n",
        "\n",
        "x=torch.randn( (batch_size, max_seq_length, d_model) ) #input\n",
        "y=torch.randn( (batch_size, max_seq_length, d_model) ) #ouput\n",
        "#look ahead mask\n",
        "mask=torch.full([max_seq_length, max_seq_length], float('-inf'))\n",
        "mask=torch.triu(mask, diagonal=1)\n",
        "\n",
        "encoder=Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "out1 = encoder(x)\n",
        "decoder=Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "out2 =decoder(x,y,mask)"
      ],
      "metadata": {
        "id": "p6Hnf0BtxrNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ddcfe7-ac57-4aea-f0d2-567c3bb78756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention: tensor([[0.0032, 0.0045, 0.0052,  ..., 0.0033, 0.0040, 0.0050],\n",
            "        [0.0064, 0.0038, 0.0060,  ..., 0.0044, 0.0057, 0.0021],\n",
            "        [0.0042, 0.0043, 0.0083,  ..., 0.0036, 0.0046, 0.0031],\n",
            "        ...,\n",
            "        [0.0042, 0.0068, 0.0075,  ..., 0.0043, 0.0063, 0.0049],\n",
            "        [0.0072, 0.0039, 0.0025,  ..., 0.0033, 0.0042, 0.0066],\n",
            "        [0.0033, 0.0046, 0.0068,  ..., 0.0034, 0.0055, 0.0056]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.0618, -0.0036, -0.0387,  ...,  0.0700, -0.0809,  0.0719],\n",
            "        [ 0.0814, -0.0066, -0.0117,  ...,  0.0872, -0.0855,  0.0614],\n",
            "        [ 0.0715, -0.0074, -0.0275,  ...,  0.0557, -0.0701,  0.0561],\n",
            "        ...,\n",
            "        [ 0.0532,  0.0069, -0.0285,  ...,  0.0807, -0.0692,  0.0312],\n",
            "        [ 0.0412, -0.0362, -0.0360,  ...,  0.0591, -0.0933,  0.0572],\n",
            "        [ 0.0709, -0.0192, -0.0076,  ...,  0.0358, -0.0726,  0.0461]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0059, 0.0040, 0.0045,  ..., 0.0063, 0.0042, 0.0043],\n",
            "        [0.0032, 0.0062, 0.0041,  ..., 0.0027, 0.0065, 0.0063],\n",
            "        [0.0050, 0.0059, 0.0053,  ..., 0.0056, 0.0051, 0.0055],\n",
            "        ...,\n",
            "        [0.0082, 0.0051, 0.0050,  ..., 0.0032, 0.0033, 0.0037],\n",
            "        [0.0031, 0.0030, 0.0055,  ..., 0.0043, 0.0025, 0.0041],\n",
            "        [0.0068, 0.0068, 0.0054,  ..., 0.0054, 0.0124, 0.0065]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0184,  0.0832, -0.0416,  ..., -0.0140, -0.0789, -0.0884],\n",
            "        [-0.0242,  0.0673, -0.0124,  ..., -0.0112, -0.1033, -0.1194],\n",
            "        [-0.0247,  0.0936, -0.0331,  ..., -0.0252, -0.0933, -0.1059],\n",
            "        ...,\n",
            "        [-0.0184,  0.0826, -0.0274,  ..., -0.0128, -0.0877, -0.0897],\n",
            "        [ 0.0064,  0.0523, -0.0256,  ..., -0.0089, -0.0992, -0.1042],\n",
            "        [-0.0196,  0.0777, -0.0354,  ..., -0.0193, -0.0534, -0.0968]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0078, 0.0053, 0.0027,  ..., 0.0049, 0.0040, 0.0038],\n",
            "        [0.0035, 0.0073, 0.0067,  ..., 0.0053, 0.0060, 0.0048],\n",
            "        [0.0106, 0.0063, 0.0049,  ..., 0.0032, 0.0033, 0.0039],\n",
            "        ...,\n",
            "        [0.0070, 0.0035, 0.0031,  ..., 0.0034, 0.0056, 0.0050],\n",
            "        [0.0045, 0.0110, 0.0042,  ..., 0.0021, 0.0053, 0.0083],\n",
            "        [0.0058, 0.0041, 0.0033,  ..., 0.0036, 0.0041, 0.0048]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0241,  0.0428, -0.0008,  ...,  0.0138,  0.0940,  0.0132],\n",
            "        [-0.0345,  0.0204,  0.0259,  ...,  0.0215,  0.0842, -0.0205],\n",
            "        [-0.0479,  0.0442,  0.0414,  ...,  0.0323,  0.0836,  0.0138],\n",
            "        ...,\n",
            "        [-0.0262,  0.0116,  0.0285,  ...,  0.0501,  0.0961, -0.0067],\n",
            "        [-0.0249,  0.0062,  0.0656,  ...,  0.0220,  0.1067, -0.0223],\n",
            "        [-0.0400,  0.0364,  0.0299,  ...,  0.0492,  0.0964,  0.0002]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0054, 0.0064, 0.0049,  ..., 0.0046, 0.0078, 0.0033],\n",
            "        [0.0039, 0.0050, 0.0027,  ..., 0.0046, 0.0039, 0.0037],\n",
            "        [0.0025, 0.0035, 0.0028,  ..., 0.0044, 0.0030, 0.0036],\n",
            "        ...,\n",
            "        [0.0034, 0.0051, 0.0044,  ..., 0.0041, 0.0075, 0.0039],\n",
            "        [0.0059, 0.0044, 0.0046,  ..., 0.0045, 0.0034, 0.0039],\n",
            "        [0.0051, 0.0048, 0.0062,  ..., 0.0033, 0.0032, 0.0057]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-1.0827e-01, -3.2456e-02, -6.7364e-03,  ..., -5.7468e-02,\n",
            "          5.7326e-02, -1.5308e-02],\n",
            "        [-1.1395e-01, -1.8440e-02, -5.0115e-02,  ..., -6.9050e-02,\n",
            "          6.4394e-02, -4.4878e-02],\n",
            "        [-9.7907e-02, -4.4684e-02, -6.3165e-03,  ..., -8.2261e-02,\n",
            "          5.7715e-02, -2.4179e-02],\n",
            "        ...,\n",
            "        [-1.0688e-01, -2.8839e-02, -2.8094e-02,  ..., -7.1089e-02,\n",
            "          6.0022e-02, -3.2061e-02],\n",
            "        [-1.1676e-01, -3.5013e-02, -2.0499e-05,  ..., -9.4263e-02,\n",
            "          8.2582e-02, -5.1432e-03],\n",
            "        [-1.0605e-01, -2.1207e-02, -1.7904e-02,  ..., -4.6009e-02,\n",
            "          8.1199e-02, -4.4944e-02]], grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0065, 0.0037, 0.0070,  ..., 0.0040, 0.0054, 0.0038],\n",
            "        [0.0054, 0.0067, 0.0027,  ..., 0.0036, 0.0047, 0.0032],\n",
            "        [0.0050, 0.0053, 0.0045,  ..., 0.0050, 0.0033, 0.0034],\n",
            "        ...,\n",
            "        [0.0042, 0.0050, 0.0065,  ..., 0.0073, 0.0047, 0.0067],\n",
            "        [0.0057, 0.0040, 0.0058,  ..., 0.0037, 0.0078, 0.0068],\n",
            "        [0.0044, 0.0034, 0.0042,  ..., 0.0069, 0.0040, 0.0095]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.1894,  0.1039, -0.1156,  ...,  0.0099,  0.2580, -0.0039],\n",
            "        [-0.1755,  0.1240, -0.1312,  ...,  0.0181,  0.2110, -0.0232],\n",
            "        [-0.2034,  0.1222, -0.1330,  ...,  0.0499,  0.2036, -0.0067],\n",
            "        ...,\n",
            "        [-0.1681,  0.1337, -0.1196,  ...,  0.0059,  0.2297, -0.0295],\n",
            "        [-0.1896,  0.1221, -0.1220,  ...,  0.0047,  0.2301, -0.0260],\n",
            "        [-0.1761,  0.1263, -0.1304,  ...,  0.0384,  0.2182, -0.0290]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0052, 0.0045, 0.0034,  ..., 0.0073, 0.0061, 0.0025],\n",
            "        [0.0066, 0.0057, 0.0043,  ..., 0.0042, 0.0077, 0.0092],\n",
            "        [0.0036, 0.0048, 0.0053,  ..., 0.0050, 0.0057, 0.0077],\n",
            "        ...,\n",
            "        [0.0037, 0.0049, 0.0056,  ..., 0.0042, 0.0052, 0.0034],\n",
            "        [0.0074, 0.0052, 0.0032,  ..., 0.0063, 0.0035, 0.0059],\n",
            "        [0.0038, 0.0053, 0.0074,  ..., 0.0037, 0.0026, 0.0060]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0999, -0.0531,  0.0233,  ...,  0.0164, -0.0127, -0.0131],\n",
            "        [-0.0890, -0.0366,  0.0766,  ..., -0.0054, -0.0009, -0.0092],\n",
            "        [-0.1002, -0.0609,  0.0897,  ...,  0.0016,  0.0103, -0.0168],\n",
            "        ...,\n",
            "        [-0.1092, -0.0693,  0.0425,  ..., -0.0243, -0.0143, -0.0201],\n",
            "        [-0.0866, -0.0659,  0.0551,  ..., -0.0022, -0.0141, -0.0261],\n",
            "        [-0.0866, -0.0969,  0.0606,  ...,  0.0021,  0.0182, -0.0151]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0071, 0.0047, 0.0043,  ..., 0.0062, 0.0042, 0.0025],\n",
            "        [0.0022, 0.0053, 0.0045,  ..., 0.0037, 0.0056, 0.0071],\n",
            "        [0.0032, 0.0047, 0.0067,  ..., 0.0043, 0.0031, 0.0058],\n",
            "        ...,\n",
            "        [0.0042, 0.0042, 0.0044,  ..., 0.0052, 0.0069, 0.0072],\n",
            "        [0.0055, 0.0036, 0.0052,  ..., 0.0059, 0.0034, 0.0057],\n",
            "        [0.0032, 0.0045, 0.0077,  ..., 0.0033, 0.0040, 0.0053]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0676, -0.0620,  0.1230,  ..., -0.0687, -0.0364, -0.1360],\n",
            "        [-0.0894, -0.0461,  0.0909,  ..., -0.0891, -0.0082, -0.1135],\n",
            "        [-0.1361, -0.0333,  0.0643,  ..., -0.0791, -0.0207, -0.1203],\n",
            "        ...,\n",
            "        [-0.1250, -0.0575,  0.0847,  ..., -0.1012, -0.0250, -0.1304],\n",
            "        [-0.1046, -0.0730,  0.1004,  ..., -0.1029, -0.0198, -0.1270],\n",
            "        [-0.1016, -0.0195,  0.0728,  ..., -0.1020,  0.0009, -0.1017]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0033, 0.0065, 0.0036,  ..., 0.0067, 0.0041, 0.0049],\n",
            "        [0.0042, 0.0050, 0.0045,  ..., 0.0052, 0.0043, 0.0056],\n",
            "        [0.0053, 0.0041, 0.0063,  ..., 0.0028, 0.0032, 0.0050],\n",
            "        ...,\n",
            "        [0.0057, 0.0065, 0.0038,  ..., 0.0068, 0.0058, 0.0054],\n",
            "        [0.0064, 0.0070, 0.0070,  ..., 0.0051, 0.0061, 0.0019],\n",
            "        [0.0032, 0.0061, 0.0058,  ..., 0.0044, 0.0057, 0.0073]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0050,  0.1957,  0.0443,  ...,  0.0656, -0.0033, -0.0509],\n",
            "        [-0.0536,  0.2048,  0.0567,  ...,  0.0420,  0.0251, -0.0606],\n",
            "        [ 0.0080,  0.1695,  0.0572,  ...,  0.0664,  0.0624, -0.0761],\n",
            "        ...,\n",
            "        [ 0.0146,  0.2168,  0.0299,  ...,  0.0745,  0.0414, -0.0672],\n",
            "        [-0.0318,  0.2068,  0.0495,  ...,  0.0802,  0.0067, -0.0599],\n",
            "        [ 0.0129,  0.1605,  0.0607,  ...,  0.0622,  0.0453, -0.0832]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0111, 0.0052, 0.0035,  ..., 0.0056, 0.0043, 0.0054],\n",
            "        [0.0044, 0.0050, 0.0050,  ..., 0.0062, 0.0035, 0.0051],\n",
            "        [0.0028, 0.0045, 0.0030,  ..., 0.0104, 0.0054, 0.0058],\n",
            "        ...,\n",
            "        [0.0042, 0.0044, 0.0043,  ..., 0.0029, 0.0053, 0.0040],\n",
            "        [0.0132, 0.0041, 0.0060,  ..., 0.0061, 0.0057, 0.0045],\n",
            "        [0.0036, 0.0054, 0.0026,  ..., 0.0042, 0.0030, 0.0051]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.0020,  0.0324,  0.0060,  ..., -0.0050,  0.1103,  0.2698],\n",
            "        [ 0.0218,  0.0369,  0.0073,  ..., -0.0352,  0.1327,  0.2782],\n",
            "        [ 0.0004,  0.0381, -0.0027,  ..., -0.0400,  0.1016,  0.2524],\n",
            "        ...,\n",
            "        [ 0.0190,  0.0199, -0.0121,  ..., -0.0280,  0.1074,  0.2781],\n",
            "        [ 0.0018,  0.0477, -0.0149,  ..., -0.0233,  0.0867,  0.3199],\n",
            "        [-0.0169,  0.0373, -0.0299,  ..., -0.0503,  0.1036,  0.2807]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0045, 0.0029, 0.0039,  ..., 0.0069, 0.0039, 0.0061],\n",
            "        [0.0057, 0.0034, 0.0040,  ..., 0.0069, 0.0050, 0.0062],\n",
            "        [0.0034, 0.0033, 0.0039,  ..., 0.0080, 0.0076, 0.0047],\n",
            "        ...,\n",
            "        [0.0055, 0.0045, 0.0043,  ..., 0.0076, 0.0029, 0.0109],\n",
            "        [0.0038, 0.0045, 0.0024,  ..., 0.0076, 0.0047, 0.0031],\n",
            "        [0.0041, 0.0036, 0.0036,  ..., 0.0061, 0.0046, 0.0055]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.1977, -0.0120,  0.0292,  ...,  0.0247, -0.1327, -0.1178],\n",
            "        [-0.1779,  0.0005,  0.0204,  ..., -0.0003, -0.1501, -0.1559],\n",
            "        [-0.2006, -0.0026,  0.0339,  ...,  0.0115, -0.1398, -0.1409],\n",
            "        ...,\n",
            "        [-0.2111, -0.0044,  0.0374,  ...,  0.0184, -0.1423, -0.1634],\n",
            "        [-0.1820,  0.0049,  0.0620,  ..., -0.0076, -0.1419, -0.1379],\n",
            "        [-0.1999,  0.0022,  0.0191,  ...,  0.0303, -0.1236, -0.1393]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer= Transformer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "out3=transformer(x, y, mask)"
      ],
      "metadata": {
        "id": "lGKb9V_EEF-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f735666c-19f6-401b-a593-11f665a43902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention: tensor([[0.0074, 0.0101, 0.0035,  ..., 0.0061, 0.0070, 0.0046],\n",
            "        [0.0056, 0.0073, 0.0058,  ..., 0.0034, 0.0031, 0.0054],\n",
            "        [0.0024, 0.0078, 0.0061,  ..., 0.0036, 0.0035, 0.0064],\n",
            "        ...,\n",
            "        [0.0034, 0.0060, 0.0054,  ..., 0.0058, 0.0028, 0.0034],\n",
            "        [0.0066, 0.0090, 0.0055,  ..., 0.0042, 0.0047, 0.0043],\n",
            "        [0.0077, 0.0053, 0.0030,  ..., 0.0058, 0.0036, 0.0032]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0255, -0.0141, -0.0201,  ...,  0.0431, -0.0645,  0.0042],\n",
            "        [ 0.0054, -0.0365,  0.0092,  ...,  0.0208, -0.0529,  0.0346],\n",
            "        [ 0.0262, -0.0643,  0.0592,  ...,  0.0459, -0.0875,  0.0373],\n",
            "        ...,\n",
            "        [ 0.0196, -0.0524,  0.0473,  ...,  0.0376, -0.0476,  0.0319],\n",
            "        [ 0.0013, -0.0361,  0.0178,  ...,  0.0379, -0.0783,  0.0283],\n",
            "        [-0.0079, -0.0458,  0.0225,  ...,  0.0165, -0.0635, -0.0593]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0033, 0.0046, 0.0049,  ..., 0.0035, 0.0047, 0.0043],\n",
            "        [0.0056, 0.0039, 0.0046,  ..., 0.0034, 0.0046, 0.0071],\n",
            "        [0.0036, 0.0035, 0.0077,  ..., 0.0061, 0.0064, 0.0033],\n",
            "        ...,\n",
            "        [0.0034, 0.0063, 0.0036,  ..., 0.0041, 0.0047, 0.0054],\n",
            "        [0.0048, 0.0026, 0.0032,  ..., 0.0051, 0.0047, 0.0056],\n",
            "        [0.0062, 0.0037, 0.0038,  ..., 0.0026, 0.0038, 0.0041]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-2.0349e-02, -2.2024e-02,  3.8633e-03,  ...,  6.1024e-02,\n",
            "          1.2452e-01,  7.6271e-02],\n",
            "        [-4.1486e-02, -7.2663e-03,  3.6240e-02,  ...,  3.5996e-02,\n",
            "          1.3120e-01,  5.5528e-02],\n",
            "        [-3.4488e-02,  2.3928e-02,  2.9151e-02,  ...,  4.9166e-02,\n",
            "          1.3941e-01,  4.2783e-02],\n",
            "        ...,\n",
            "        [-5.0821e-02,  9.5324e-03,  1.1964e-03,  ...,  6.8314e-02,\n",
            "          9.0869e-02,  7.4737e-02],\n",
            "        [-4.1784e-02,  3.7288e-03, -1.8072e-02,  ...,  3.0097e-02,\n",
            "          1.2843e-01,  7.2361e-02],\n",
            "        [-2.0632e-02, -9.7350e-03,  1.3561e-04,  ...,  6.0932e-02,\n",
            "          1.2609e-01,  3.9978e-02]], grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0031, 0.0029, 0.0034,  ..., 0.0034, 0.0028, 0.0055],\n",
            "        [0.0063, 0.0044, 0.0045,  ..., 0.0031, 0.0068, 0.0068],\n",
            "        [0.0085, 0.0042, 0.0035,  ..., 0.0034, 0.0017, 0.0048],\n",
            "        ...,\n",
            "        [0.0045, 0.0060, 0.0046,  ..., 0.0067, 0.0049, 0.0077],\n",
            "        [0.0032, 0.0036, 0.0053,  ..., 0.0044, 0.0048, 0.0047],\n",
            "        [0.0065, 0.0036, 0.0051,  ..., 0.0089, 0.0058, 0.0027]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.2806, -0.0886,  0.1146,  ...,  0.0116,  0.0747, -0.0881],\n",
            "        [-0.2653, -0.1125,  0.1007,  ...,  0.0274,  0.0778, -0.0966],\n",
            "        [-0.2617, -0.0568,  0.0890,  ..., -0.0068,  0.0744, -0.1004],\n",
            "        ...,\n",
            "        [-0.2352, -0.0925,  0.1144,  ..., -0.0103,  0.0485, -0.1176],\n",
            "        [-0.2603, -0.0649,  0.0771,  ...,  0.0298,  0.0550, -0.0931],\n",
            "        [-0.2662, -0.0641,  0.0942,  ...,  0.0098,  0.0566, -0.0809]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0046, 0.0070, 0.0081,  ..., 0.0048, 0.0061, 0.0033],\n",
            "        [0.0037, 0.0022, 0.0039,  ..., 0.0057, 0.0073, 0.0071],\n",
            "        [0.0055, 0.0036, 0.0044,  ..., 0.0045, 0.0074, 0.0062],\n",
            "        ...,\n",
            "        [0.0064, 0.0054, 0.0045,  ..., 0.0052, 0.0053, 0.0048],\n",
            "        [0.0047, 0.0040, 0.0059,  ..., 0.0074, 0.0052, 0.0023],\n",
            "        [0.0041, 0.0079, 0.0034,  ..., 0.0036, 0.0066, 0.0043]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0915, -0.0840,  0.0305,  ..., -0.0604, -0.1658,  0.1730],\n",
            "        [-0.0748, -0.0836,  0.0121,  ..., -0.0682, -0.1537,  0.1484],\n",
            "        [-0.0762, -0.0947,  0.0115,  ..., -0.0430, -0.1383,  0.1480],\n",
            "        ...,\n",
            "        [-0.0640, -0.1082,  0.0101,  ..., -0.0263, -0.1342,  0.1391],\n",
            "        [-0.0785, -0.1148,  0.0120,  ..., -0.0459, -0.1293,  0.1498],\n",
            "        [-0.0997, -0.0936,  0.0300,  ..., -0.0389, -0.1481,  0.1617]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0057, 0.0032, 0.0043,  ..., 0.0053, 0.0050, 0.0034],\n",
            "        [0.0042, 0.0051, 0.0053,  ..., 0.0064, 0.0085, 0.0036],\n",
            "        [0.0021, 0.0051, 0.0053,  ..., 0.0031, 0.0066, 0.0033],\n",
            "        ...,\n",
            "        [0.0043, 0.0041, 0.0067,  ..., 0.0032, 0.0072, 0.0050],\n",
            "        [0.0039, 0.0035, 0.0061,  ..., 0.0039, 0.0079, 0.0040],\n",
            "        [0.0043, 0.0051, 0.0065,  ..., 0.0050, 0.0078, 0.0055]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.0926,  0.1643,  0.1531,  ..., -0.1053, -0.0120,  0.1729],\n",
            "        [ 0.0451,  0.1757,  0.1326,  ..., -0.1187, -0.0386,  0.1960],\n",
            "        [ 0.0517,  0.1877,  0.1569,  ..., -0.1187, -0.0168,  0.1878],\n",
            "        ...,\n",
            "        [ 0.0490,  0.1824,  0.1381,  ..., -0.1184, -0.0037,  0.1989],\n",
            "        [ 0.0671,  0.1434,  0.1442,  ..., -0.1237, -0.0067,  0.2110],\n",
            "        [ 0.0564,  0.1553,  0.1592,  ..., -0.1451, -0.0085,  0.1801]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0078, 0.0126, 0.0026,  ..., 0.0053, 0.0058, 0.0044],\n",
            "        [0.0051, 0.0080, 0.0046,  ..., 0.0030, 0.0037, 0.0045],\n",
            "        [0.0033, 0.0069, 0.0034,  ..., 0.0038, 0.0063, 0.0025],\n",
            "        ...,\n",
            "        [0.0046, 0.0043, 0.0032,  ..., 0.0039, 0.0078, 0.0053],\n",
            "        [0.0049, 0.0053, 0.0037,  ..., 0.0065, 0.0051, 0.0040],\n",
            "        [0.0052, 0.0067, 0.0061,  ..., 0.0035, 0.0044, 0.0030]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.0292, -0.0395,  0.0401,  ..., -0.0731,  0.0302,  0.0513],\n",
            "        [ 0.0170, -0.0257,  0.0206,  ..., -0.0588,  0.0374,  0.0755],\n",
            "        [ 0.0406, -0.0007,  0.0318,  ..., -0.0419,  0.0092,  0.0594],\n",
            "        ...,\n",
            "        [ 0.0398, -0.0057,  0.0547,  ..., -0.0618,  0.0240,  0.0619],\n",
            "        [ 0.0193, -0.0590,  0.0499,  ..., -0.0633,  0.0627,  0.0667],\n",
            "        [ 0.0273, -0.0314,  0.0631,  ..., -0.0434,  0.0584,  0.0561]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0055, 0.0088, 0.0088,  ..., 0.0052, 0.0032, 0.0070],\n",
            "        [0.0069, 0.0036, 0.0048,  ..., 0.0056, 0.0032, 0.0058],\n",
            "        [0.0036, 0.0059, 0.0057,  ..., 0.0031, 0.0050, 0.0090],\n",
            "        ...,\n",
            "        [0.0029, 0.0053, 0.0041,  ..., 0.0055, 0.0039, 0.0082],\n",
            "        [0.0031, 0.0064, 0.0027,  ..., 0.0053, 0.0023, 0.0040],\n",
            "        [0.0041, 0.0020, 0.0057,  ..., 0.0040, 0.0032, 0.0043]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0611,  0.0866, -0.1481,  ..., -0.1525,  0.0603, -0.1970],\n",
            "        [-0.0368,  0.0902, -0.1348,  ..., -0.1715,  0.0637, -0.2051],\n",
            "        [-0.0479,  0.0556, -0.1657,  ..., -0.1319,  0.0337, -0.1989],\n",
            "        ...,\n",
            "        [-0.0442,  0.0676, -0.1465,  ..., -0.1448,  0.0392, -0.1941],\n",
            "        [-0.0432,  0.1099, -0.1385,  ..., -0.1540,  0.0500, -0.1885],\n",
            "        [-0.0549,  0.0916, -0.1349,  ..., -0.1664,  0.0411, -0.1934]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0037, 0.0020, 0.0043,  ..., 0.0050, 0.0058, 0.0048],\n",
            "        [0.0073, 0.0064, 0.0032,  ..., 0.0049, 0.0043, 0.0047],\n",
            "        [0.0070, 0.0093, 0.0058,  ..., 0.0031, 0.0079, 0.0033],\n",
            "        ...,\n",
            "        [0.0040, 0.0067, 0.0051,  ..., 0.0061, 0.0031, 0.0034],\n",
            "        [0.0040, 0.0066, 0.0038,  ..., 0.0060, 0.0066, 0.0029],\n",
            "        [0.0058, 0.0078, 0.0098,  ..., 0.0047, 0.0042, 0.0057]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[-0.0472,  0.0624,  0.0164,  ...,  0.1880, -0.1506,  0.0353],\n",
            "        [-0.0510,  0.1008,  0.0334,  ...,  0.1360, -0.1773,  0.0169],\n",
            "        [-0.0687,  0.0749,  0.0295,  ...,  0.1402, -0.1386, -0.0168],\n",
            "        ...,\n",
            "        [-0.0494,  0.0953,  0.0238,  ...,  0.1440, -0.1765,  0.0434],\n",
            "        [-0.0261,  0.0626,  0.0131,  ...,  0.1348, -0.1602,  0.0068],\n",
            "        [-0.0501,  0.0627,  0.0258,  ...,  0.1569, -0.1477, -0.0073]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0043, 0.0062, 0.0052,  ..., 0.0024, 0.0034, 0.0046],\n",
            "        [0.0048, 0.0035, 0.0028,  ..., 0.0029, 0.0022, 0.0044],\n",
            "        [0.0040, 0.0082, 0.0026,  ..., 0.0050, 0.0021, 0.0045],\n",
            "        ...,\n",
            "        [0.0027, 0.0052, 0.0049,  ..., 0.0051, 0.0039, 0.0033],\n",
            "        [0.0046, 0.0039, 0.0045,  ..., 0.0037, 0.0028, 0.0022],\n",
            "        [0.0060, 0.0042, 0.0054,  ..., 0.0060, 0.0043, 0.0051]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.1875, -0.1881,  0.2068,  ..., -0.3375,  0.1018,  0.0487],\n",
            "        [ 0.1911, -0.1893,  0.1859,  ..., -0.3440,  0.0944,  0.0498],\n",
            "        [ 0.1961, -0.2026,  0.2132,  ..., -0.3507,  0.1197,  0.0255],\n",
            "        ...,\n",
            "        [ 0.1846, -0.1881,  0.2104,  ..., -0.3506,  0.0816,  0.0230],\n",
            "        [ 0.2102, -0.2004,  0.1924,  ..., -0.3460,  0.1153,  0.0262],\n",
            "        [ 0.2096, -0.1975,  0.1947,  ..., -0.3357,  0.0906,  0.0309]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention: tensor([[0.0087, 0.0071, 0.0082,  ..., 0.0037, 0.0046, 0.0041],\n",
            "        [0.0038, 0.0061, 0.0045,  ..., 0.0069, 0.0048, 0.0036],\n",
            "        [0.0045, 0.0074, 0.0037,  ..., 0.0042, 0.0043, 0.0060],\n",
            "        ...,\n",
            "        [0.0047, 0.0042, 0.0046,  ..., 0.0047, 0.0066, 0.0051],\n",
            "        [0.0042, 0.0073, 0.0049,  ..., 0.0037, 0.0036, 0.0037],\n",
            "        [0.0049, 0.0037, 0.0065,  ..., 0.0055, 0.0040, 0.0037]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "attention shape tensor: torch.Size([30, 8, 200, 200])\n",
            "values: tensor([[ 0.0030, -0.0794, -0.0870,  ..., -0.1586, -0.2003,  0.0097],\n",
            "        [ 0.0389, -0.1128, -0.0622,  ..., -0.1767, -0.1980,  0.0177],\n",
            "        [ 0.0197, -0.0554, -0.0903,  ..., -0.1835, -0.1815,  0.0106],\n",
            "        ...,\n",
            "        [ 0.0322, -0.0845, -0.0675,  ..., -0.1582, -0.1936,  0.0312],\n",
            "        [ 0.0097, -0.0719, -0.0758,  ..., -0.1970, -0.1714,  0.0217],\n",
            "        [ 0.0096, -0.0896, -0.0679,  ..., -0.1717, -0.1629,  0.0213]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "KfmOuo5X6l_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}